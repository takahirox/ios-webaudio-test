<!DOCTYPE html>
<html lang="en">
<head>
  <title>iOS WebAudio simple test</title>
  <meta charset="utf-8">
</head>
<body>
  <div>
    <button id="runButton">Run</button><br />
  </div>

  <br />

  <div>
    WebAudio AudioContext constructor optional parameters<br />
    <br />
    latencyHint
    <select id="latencyHintSelect">
      <option value="None" selected>None</option>
      <option value="balanced">balanced</option>
      <option value="interactive">interactive</option>
      <option value="playback">playback</option>
    </select>
    <br />
    sampleRate <input id="sampleRateText" type="text"></input>
    <br />
    <div id="errorMessage" style="color: red"></div>
  </div>

  <br />

  <div><a href="https://github.com/takahirox/ios-webaudio-test" target="_blank">Source code</a></div>
  <div id="info">
    music by <a href="http://www.newgrounds.com/audio/listen/376737" target="_blank" rel="noopener noreferrer">skullbeatz</a>
  </div>

  <br />

  <div id="useragent"></div>

  <script type="module">
    const videoFileURL = 'videos/sintel.mp4';

    const disableElements = () => {
      document.getElementById('runButton').disabled = true;
      document.getElementById('latencyHintSelect').disabled = true;
      document.getElementById('sampleRateText').disabled = true;
    };

    const getUserMediaStream = async () => {
      return await navigator.mediaDevices.getUserMedia({audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
	  }});
    };

    const createVideoElement = () => {
      const videoElement = document.createElement('video');
      videoElement.setAttribute('playsinline', '');
      videoElement.setAttribute('webkit-playsinline', '');
      videoElement.loop = true;
      videoElement.preload = 'auto';
      videoElement.autoplay = true;
      videoElement.crossOrigin = 'anonymous';
      videoElement.src = videoFileURL;
      videoElement.load(); // This seems to be necessary for iOS Safari
      return videoElement;
    };

    const createAudioContext = () => {
      const options = {};

      const latencyHintSelect = document.getElementById('latencyHintSelect');
      const sampleRateText = document.getElementById('sampleRateText');

      const latencyHintOption = latencyHintSelect.options[latencyHintSelect.selectedIndex];
      const sampleRateValue = sampleRateText.value;

      if (latencyHintOption.value !== 'None') { options.latencyHint = latencyHintOption.value; }
      if (sampleRateValue !== '') { options.sampleRate = parseInt(sampleRateValue); }

      console.log('AudioContext constructor parameters', options);

      return new (window.AudioContext || window.webkitAudioContext)(options);
    };

    const run = async () => {
      disableElements();

      try {
        const context = createAudioContext();

        // mic audio stream
        const mediaStreamDestinationNode = context.createMediaStreamDestination();
        const outboundStream = mediaStreamDestinationNode.stream;
        const outboundGainNode = context.createGain();
        const outboundAnalyser = context.createAnalyser();
        outboundAnalyser.fftSize = 32;
        const analyserLevels = new Uint8Array(outboundAnalyser.fftSize);
        outboundGainNode.connect(outboundAnalyser);
        outboundAnalyser.connect(mediaStreamDestinationNode);

        getUserMediaStream().then(stream => {
          const sourceStream = context.createMediaStreamSource(stream);
          const streamGainNode = context.createGain();
          sourceStream.connect(streamGainNode);
          streamGainNode.connect(outboundGainNode);
        });

        // video
        const videoElement = createVideoElement();
        videoElement.addEventListener('error', onError);

        const source = context.createMediaElementSource(videoElement);
        const gain = context.createGain(); // audio output
        const gain2 = context.createGain(); // listener input
        source.connect(gain);
        gain.connect(gain2);
        gain2.connect(context.destination);

        // addAudio()
        const gain3 = context.createGain();
        gain3.connect(gain2);
        gain.connect(gain3);

        document.body.appendChild(videoElement);

        const periodicallyRun = () => {
          requestAnimationFrame(periodicallyRun);
          gain.gain.setTargetAtTime(1.0, context.currentTime, 0.01);
          const listener = context.listener;
          const endTime = context.currentTime + 0.01;
          listener.positionX.linearRampToValueAtTime(0, endTime);
          listener.positionY.linearRampToValueAtTime(0, endTime);
          listener.positionZ.linearRampToValueAtTime(0, endTime);
          listener.forwardX.linearRampToValueAtTime(0, endTime);
          listener.forwardY.linearRampToValueAtTime(0, endTime);
          listener.forwardZ.linearRampToValueAtTime(-1, endTime);
          listener.upX.linearRampToValueAtTime(0, endTime);
          listener.upY.linearRampToValueAtTime(1, endTime);
          listener.upZ.linearRampToValueAtTime(0, endTime);
        };
        periodicallyRun();
      } catch (e) {
        onError(e);
      }
    };

    const onError = e => {
      document.getElementById('errorMessage').innerText = e.message;
      console.error(e);
    };

    document.getElementById('runButton').addEventListener('click', run);
    document.getElementById('useragent').innerText = navigator.userAgent;
  </script>
</body>
</html>
